# Platform Description

GLOBEM provides three major modules and a few utility functions:
1. `Feature Preparation Module`
2. `Model Computatoin Module`
3. `Configuration Module`

Each algorithm (`DepressionDetectionAlgorithmBase` defined in [`algorithm/base.py`](https://github.com/UW-EXP/GLOBEM/tree/main/algorithm/base.py)) consists of these three modules 
to form a complete pipeline that leads to one (or more) machine learning models: 
from feature preparation (as model input) to model computation (to obtain model output), with parameters controlled by the configuration module.

## Input

After dataset preparation (as explained in [Setup](/platform/tutorial/setup) page), an initial input data point will be a standard (`feature matrix`, `label`) pair.

`label`: the ground truth (currently, it is a binary label) indicating a subject's self-report depressive symptom status on a certain date.

`feature matrix`: given the date of the `label`, the feature matrix includes daily feature vectors in the past four weeks, with the dimension as `(28, # of features)`.

## Feature Preparation Module

This module defines the features used by the algorithm as the input. 
The function `DepressionDetectionAlgorithmBase.prep_data_repo` determines this process of an algorithm.

For traditional machine learning algorithms, 
this can be basic feature selection, aggregation, and filtering (*e.g.,* mean, std) along the feature matrix's temporal dimension
 (*e.g.,* [Canzian *et al.*](https://github.com/UW-EXP/GLOBEM/tree/main/algorithm/ml_canzian.py), [Saeb *et al.*](https://github.com/UW-EXP/GLOBEM/tree/main/algorithm/ml_saeb.py)), 
or complex feature extraction
 (*e.g.,* [Xu *et al.*](https://github.com/UW-EXP/GLOBEM/tree/main/algorithm/ml_xu_interpretable.py), [Chikersal *et al.*](https://github.com/UW-EXP/GLOBEM/tree/main/algorithm/ml_chikersal.py)).

For deep learning algorithms, 
this is a definition of a feature data feeding process (*i.e.,* a data generator) 
that prepares data for deep model training (*e.g.,* [ERM](https://github.com/UW-EXP/GLOBEM/tree/main/algorithm/dl_erm.py)).

## Model Computation Module

This module defines the model construction and training process. 
The function `DepressionDetectionAlgorithmBase.prep_model` determines a prediction model generated by the algorithm. 
The `prep_model` function will return a `DepressionDetectionClassifierBase` object that specifies the model design, training, and prediction process.

For traditional machine learning algorithms, 
this can be some off-the-shelf model such as an SVM (*e.g.,* [Farhan *et al.*](https://github.com/UW-EXP/GLOBEM/tree/main/algorithm/ml_farhan.py)),
 or some customized statistical model (*e.g.,* [Lu *et al.*](https://github.com/UW-EXP/GLOBEM/tree/main/algorithm/ml_lu.py)) that is ready to be trained with input data.

For deep learning algorithms,
this is a definition of deep modeling architecture and training process (*e.g.,* [IRM](https://github.com/UW-EXP/GLOBEM/tree/main/algorithm/dl_irm.py)), 
and builds a deep model that is ready to be trained with input data.

### Multiple Models from One Algorithm

It is worth noting that one algorithm can define multiple models. 

For example, [ERM](https://github.com/UW-EXP/GLOBEM/tree/main/algorithm/dl_erm.py) 
can use different deep learning architectures such as 
[ERM-1D-CNN](https://github.com/UW-EXP/GLOBEM/blob/main/config/dl_erm_1dCNN.yaml),
[ERM-2D-CNN](https://github.com/UW-EXP/GLOBEM/blob/main/config/dl_erm_2dCNN.yaml),
[ERM-Transformer](https://github.com/UW-EXP/GLOBEM/blob/main/config/dl_erm_Transformer.yaml);
[DANN](https://github.com/UW-EXP/GLOBEM/tree/main/algorithm/dl_dann.py) can take each dataset as a domain
([DANN-dataset as domain](https://github.com/UW-EXP/GLOBEM/blob/main/config/dl_dann_ds_as_domain.yaml)),
or each person as a domain ([DANN-person as domain](https://github.com/UW-EXP/GLOBEM/blob/main/config/dl_dann_person_as_domain.yaml)).

This is controlled by the config files and the [`algorithm_factory`](https://github.com/UW-EXP/GLOBEM/blob/main/algorithm/algorithm_factory.py).
The [next page](/platform/tutorial/extendplatform) introduces how the two parts work together.

## Configuration Module

This module provides the flexibility of controlling different parameters in the `Feature Preparation Module` and `Model Computation Module`.
Each algorithm has its own unique parameters that can be added to this module.

The platform employs a simple `yaml` file system. 
Each model (*NOT algorithm*) has its own unique config yaml file in [`config`](https://github.com/UW-EXP/GLOBEM/tree/main/config) folder with a unique file name. 

For example, [Chikersal *et al.*](https://github.com/UW-EXP/GLOBEM/tree/main/algorithm/ml_chikersal.py) can have one model, 
and its config file is [`config/ml_chikersal.yaml`](https://github.com/UW-EXP/GLOBEM/tree/main/config/ml_chikersal.yaml); 
[DANN](https://github.com/UW-EXP/GLOBEM/tree/main/algorithm/dl_dann.py) can have two models,
    so it has two config files: [`config/dl_dann_ds_as_domain.yaml`](https://github.com/UW-EXP/GLOBEM/tree/main/config/dl_dann_ds_as_domain.yaml) 
    and [`config/dl_dann_person_as_domain.yaml`](https://github.com/UW-EXP/GLOBEM/tree/main/config/dl_dann_person_as_domain.yaml), respectively.
